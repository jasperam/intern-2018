{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1: circle data\n",
      "Prediction:\n",
      "[[0.46756124]\n",
      " [0.46786496]\n",
      " [0.47873887]\n",
      " [0.4490777 ]\n",
      " [0.0948275 ]], \n",
      "True label:\n",
      "[1. 0. 1. 0. 0.], \n",
      "Loss:0.806, \n",
      "Accuracy:60.20%\n",
      "Prediction:\n",
      "[[0.9579441 ]\n",
      " [0.68407977]\n",
      " [0.94398355]\n",
      " [0.00131212]\n",
      " [0.00207466]], \n",
      "True label:\n",
      "[1. 0. 1. 0. 0.], \n",
      "Loss:1.941, \n",
      "Accuracy:97.20%\n",
      "Prediction:\n",
      "[[9.6058297e-01]\n",
      " [8.3300173e-01]\n",
      " [9.5983595e-01]\n",
      " [7.9232886e-05]\n",
      " [5.1407947e-04]], \n",
      "True label:\n",
      "[1. 0. 1. 0. 0.], \n",
      "Loss:2.374, \n",
      "Accuracy:97.20%\n",
      "Prediction:\n",
      "[[9.5406014e-01]\n",
      " [9.0413362e-01]\n",
      " [9.5413685e-01]\n",
      " [1.1829797e-05]\n",
      " [2.7639128e-04]], \n",
      "True label:\n",
      "[1. 0. 1. 0. 0.], \n",
      "Loss:2.584, \n",
      "Accuracy:97.20%\n",
      "Prediction:\n",
      "[[9.5099413e-01]\n",
      " [9.4130415e-01]\n",
      " [9.5090544e-01]\n",
      " [3.6380425e-06]\n",
      " [1.5433365e-04]], \n",
      "True label:\n",
      "[1. 0. 1. 0. 0.], \n",
      "Loss:2.751, \n",
      "Accuracy:97.20%\n",
      "Prediction:\n",
      "[[9.49719489e-01]\n",
      " [9.45693731e-01]\n",
      " [9.49529290e-01]\n",
      " [1.80533277e-06]\n",
      " [1.06330066e-04]], \n",
      "True label:\n",
      "[1. 0. 1. 0. 0.], \n",
      "Loss:2.880, \n",
      "Accuracy:97.20%\n",
      "Prediction:\n",
      "[[9.4887894e-01]\n",
      " [9.4559258e-01]\n",
      " [9.4859463e-01]\n",
      " [9.0864785e-07]\n",
      " [7.6286087e-05]], \n",
      "True label:\n",
      "[1. 0. 1. 0. 0.], \n",
      "Loss:2.983, \n",
      "Accuracy:97.20%\n",
      "Prediction:\n",
      "[[9.4818866e-01]\n",
      " [9.4524413e-01]\n",
      " [9.4784176e-01]\n",
      " [4.8877763e-07]\n",
      " [6.1751336e-05]], \n",
      "True label:\n",
      "[1. 0. 1. 0. 0.], \n",
      "Loss:3.069, \n",
      "Accuracy:97.20%\n",
      "Model 2: Gauss data\n",
      "Prediction:\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]], \n",
      "True label:\n",
      "[1. 1. 1. 1. 1. 0. 0. 0. 0. 0.], \n",
      "Loss:0.482, \n",
      "Accuracy:51.40%\n",
      "Prediction:\n",
      "[[0.75699717]\n",
      " [0.7140693 ]\n",
      " [0.7676481 ]\n",
      " [0.6464345 ]\n",
      " [1.1295211 ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.05695348]], \n",
      "True label:\n",
      "[1. 1. 1. 1. 1. 0. 0. 0. 0. 0.], \n",
      "Loss:0.410, \n",
      "Accuracy:99.60%\n",
      "Prediction:\n",
      "[[0.70615834]\n",
      " [0.74117434]\n",
      " [0.70639294]\n",
      " [0.6154036 ]\n",
      " [0.96991086]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]], \n",
      "True label:\n",
      "[1. 1. 1. 1. 1. 0. 0. 0. 0. 0.], \n",
      "Loss:0.403, \n",
      "Accuracy:99.00%\n",
      "Prediction:\n",
      "[[0.72356266]\n",
      " [0.75790673]\n",
      " [0.72349066]\n",
      " [0.61014956]\n",
      " [0.9206934 ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]], \n",
      "True label:\n",
      "[1. 1. 1. 1. 1. 0. 0. 0. 0. 0.], \n",
      "Loss:0.407, \n",
      "Accuracy:99.20%\n",
      "Prediction:\n",
      "[[0.73408777]\n",
      " [0.76917356]\n",
      " [0.7351126 ]\n",
      " [0.60737586]\n",
      " [0.8937977 ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]], \n",
      "True label:\n",
      "[1. 1. 1. 1. 1. 0. 0. 0. 0. 0.], \n",
      "Loss:0.409, \n",
      "Accuracy:99.20%\n",
      "Prediction:\n",
      "[[0.73899245]\n",
      " [0.772841  ]\n",
      " [0.7407708 ]\n",
      " [0.6073383 ]\n",
      " [0.87735623]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]], \n",
      "True label:\n",
      "[1. 1. 1. 1. 1. 0. 0. 0. 0. 0.], \n",
      "Loss:0.410, \n",
      "Accuracy:99.20%\n",
      "Prediction:\n",
      "[[0.74522465]\n",
      " [0.77068955]\n",
      " [0.747521  ]\n",
      " [0.6092805 ]\n",
      " [0.86125666]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]], \n",
      "True label:\n",
      "[1. 1. 1. 1. 1. 0. 0. 0. 0. 0.], \n",
      "Loss:0.410, \n",
      "Accuracy:99.20%\n",
      "Prediction:\n",
      "[[0.75534636]\n",
      " [0.76105237]\n",
      " [0.7576724 ]\n",
      " [0.61007124]\n",
      " [0.8440127 ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]], \n",
      "True label:\n",
      "[1. 1. 1. 1. 1. 0. 0. 0. 0. 0.], \n",
      "Loss:0.411, \n",
      "Accuracy:99.20%\n",
      "Model 3: xor data\n",
      "Prediction:\n",
      "[[0.48486486]\n",
      " [0.59292674]\n",
      " [0.60608846]\n",
      " [0.55442816]\n",
      " [0.4263004 ]], \n",
      "True label:\n",
      "[0. 1. 1. 1. 0.], \n",
      "Loss:0.705, \n",
      "Accuracy:75.60%\n",
      "Prediction:\n",
      "[[0.40769744]\n",
      " [0.6015095 ]\n",
      " [0.60751706]\n",
      " [0.5380112 ]\n",
      " [0.34568787]], \n",
      "True label:\n",
      "[0. 1. 1. 1. 0.], \n",
      "Loss:0.709, \n",
      "Accuracy:86.40%\n",
      "Prediction:\n",
      "[[0.4182603 ]\n",
      " [0.5994608 ]\n",
      " [0.6114275 ]\n",
      " [0.53348273]\n",
      " [0.3284071 ]], \n",
      "True label:\n",
      "[0. 1. 1. 1. 0.], \n",
      "Loss:0.709, \n",
      "Accuracy:86.00%\n",
      "Prediction:\n",
      "[[0.4141263 ]\n",
      " [0.59784496]\n",
      " [0.6094654 ]\n",
      " [0.5312995 ]\n",
      " [0.32254827]], \n",
      "True label:\n",
      "[0. 1. 1. 1. 0.], \n",
      "Loss:0.709, \n",
      "Accuracy:86.00%\n",
      "Prediction:\n",
      "[[0.40854812]\n",
      " [0.59622   ]\n",
      " [0.6063402 ]\n",
      " [0.5288658 ]\n",
      " [0.31468934]], \n",
      "True label:\n",
      "[0. 1. 1. 1. 0.], \n",
      "Loss:0.709, \n",
      "Accuracy:85.80%\n",
      "Prediction:\n",
      "[[0.40937865]\n",
      " [0.5951346 ]\n",
      " [0.60712516]\n",
      " [0.53151137]\n",
      " [0.30755872]], \n",
      "True label:\n",
      "[0. 1. 1. 1. 0.], \n",
      "Loss:0.709, \n",
      "Accuracy:85.40%\n",
      "Prediction:\n",
      "[[0.40902895]\n",
      " [0.5949385 ]\n",
      " [0.60638535]\n",
      " [0.5301808 ]\n",
      " [0.3023484 ]], \n",
      "True label:\n",
      "[0. 1. 1. 1. 0.], \n",
      "Loss:0.709, \n",
      "Accuracy:85.20%\n",
      "Prediction:\n",
      "[[0.40120158]\n",
      " [0.59358835]\n",
      " [0.60830927]\n",
      " [0.52300096]\n",
      " [0.2904107 ]], \n",
      "True label:\n",
      "[0. 1. 1. 1. 0.], \n",
      "Loss:0.710, \n",
      "Accuracy:86.60%\n",
      "Prediction:\n",
      "[[0.39561486]\n",
      " [0.59307325]\n",
      " [0.6047052 ]\n",
      " [0.5249991 ]\n",
      " [0.28558075]], \n",
      "True label:\n",
      "[0. 1. 1. 1. 0.], \n",
      "Loss:0.710, \n",
      "Accuracy:86.80%\n",
      "Prediction:\n",
      "[[0.39931265]\n",
      " [0.5933359 ]\n",
      " [0.6091339 ]\n",
      " [0.5223789 ]\n",
      " [0.28432313]], \n",
      "True label:\n",
      "[0. 1. 1. 1. 0.], \n",
      "Loss:0.710, \n",
      "Accuracy:86.60%\n",
      "Prediction:\n",
      "[[0.39855477]\n",
      " [0.5924988 ]\n",
      " [0.60596603]\n",
      " [0.52625394]\n",
      " [0.27917442]], \n",
      "True label:\n",
      "[0. 1. 1. 1. 0.], \n",
      "Loss:0.710, \n",
      "Accuracy:86.80%\n",
      "Prediction:\n",
      "[[0.39728534]\n",
      " [0.59270287]\n",
      " [0.6070153 ]\n",
      " [0.52548164]\n",
      " [0.27825692]], \n",
      "True label:\n",
      "[0. 1. 1. 1. 0.], \n",
      "Loss:0.710, \n",
      "Accuracy:86.60%\n",
      "Prediction:\n",
      "[[0.395987  ]\n",
      " [0.5929991 ]\n",
      " [0.6097144 ]\n",
      " [0.52381074]\n",
      " [0.2792794 ]], \n",
      "True label:\n",
      "[0. 1. 1. 1. 0.], \n",
      "Loss:0.710, \n",
      "Accuracy:86.60%\n",
      "Prediction:\n",
      "[[0.39219102]\n",
      " [0.59074706]\n",
      " [0.6053564 ]\n",
      " [0.5270557 ]\n",
      " [0.27461284]], \n",
      "True label:\n",
      "[0. 1. 1. 1. 0.], \n",
      "Loss:0.710, \n",
      "Accuracy:86.60%\n",
      "Model 4: spiral data\n",
      "Prediction:\n",
      "[[-0.00072633]\n",
      " [-0.00302203]\n",
      " [ 0.00429557]\n",
      " [-0.00108938]\n",
      " [-0.00230373]], \n",
      "True label:\n",
      "[1. 1. 1. 0. 0.], \n",
      "Loss:0.500, \n",
      "Accuracy:50.00%\n",
      "Prediction:\n",
      "[[ 0.05216212]\n",
      " [ 0.01717164]\n",
      " [-0.02957472]\n",
      " [ 0.01688595]\n",
      " [ 0.0502369 ]], \n",
      "True label:\n",
      "[1. 1. 1. 0. 0.], \n",
      "Loss:0.485, \n",
      "Accuracy:50.00%\n",
      "Prediction:\n",
      "[[-0.08079976]\n",
      " [-0.00578517]\n",
      " [-0.0535913 ]\n",
      " [-0.06245446]\n",
      " [-0.01394289]], \n",
      "True label:\n",
      "[1. 1. 1. 0. 0.], \n",
      "Loss:0.526, \n",
      "Accuracy:50.00%\n",
      "Prediction:\n",
      "[[-0.05957149]\n",
      " [ 0.50371575]\n",
      " [ 0.14921844]\n",
      " [-0.04549275]\n",
      " [-0.00156732]], \n",
      "True label:\n",
      "[1. 1. 1. 0. 0.], \n",
      "Loss:0.454, \n",
      "Accuracy:64.80%\n",
      "Prediction:\n",
      "[[-0.09379147]\n",
      " [-0.00240266]\n",
      " [-0.04052127]\n",
      " [-0.09300698]\n",
      " [ 0.01918019]], \n",
      "True label:\n",
      "[1. 1. 1. 0. 0.], \n",
      "Loss:0.518, \n",
      "Accuracy:50.00%\n",
      "Prediction:\n",
      "[[-0.01013934]\n",
      " [ 0.7035835 ]\n",
      " [ 0.774634  ]\n",
      " [-0.01110184]\n",
      " [ 0.03453417]], \n",
      "True label:\n",
      "[1. 1. 1. 0. 0.], \n",
      "Loss:0.413, \n",
      "Accuracy:85.60%\n",
      "Prediction:\n",
      "[[ 0.20161158]\n",
      " [ 0.6510881 ]\n",
      " [ 0.7067634 ]\n",
      " [-0.01336514]\n",
      " [-0.00433808]], \n",
      "True label:\n",
      "[1. 1. 1. 0. 0.], \n",
      "Loss:0.381, \n",
      "Accuracy:80.80%\n",
      "Prediction:\n",
      "[[ 0.30643982]\n",
      " [ 0.73472404]\n",
      " [ 0.82513165]\n",
      " [-0.00981354]\n",
      " [-0.00254252]], \n",
      "True label:\n",
      "[1. 1. 1. 0. 0.], \n",
      "Loss:0.416, \n",
      "Accuracy:94.80%\n",
      "Prediction:\n",
      "[[ 0.3859983 ]\n",
      " [-0.00805683]\n",
      " [ 0.6781013 ]\n",
      " [-0.12893805]\n",
      " [-0.1339528 ]], \n",
      "True label:\n",
      "[1. 1. 1. 0. 0.], \n",
      "Loss:0.453, \n",
      "Accuracy:67.20%\n",
      "Prediction:\n",
      "[[ 0.59061515]\n",
      " [ 0.91330945]\n",
      " [ 0.9874172 ]\n",
      " [-0.01642063]\n",
      " [-0.03593834]], \n",
      "True label:\n",
      "[1. 1. 1. 0. 0.], \n",
      "Loss:0.463, \n",
      "Accuracy:99.00%\n",
      "Prediction:\n",
      "[[ 0.6787815 ]\n",
      " [ 0.9302901 ]\n",
      " [ 0.94731236]\n",
      " [-0.01097047]\n",
      " [-0.02767057]], \n",
      "True label:\n",
      "[1. 1. 1. 0. 0.], \n",
      "Loss:0.471, \n",
      "Accuracy:98.80%\n",
      "Prediction:\n",
      "[[ 0.75711787]\n",
      " [ 0.9384774 ]\n",
      " [ 0.9536152 ]\n",
      " [-0.00704262]\n",
      " [-0.0221664 ]], \n",
      "True label:\n",
      "[1. 1. 1. 0. 0.], \n",
      "Loss:0.475, \n",
      "Accuracy:99.00%\n",
      "Prediction:\n",
      "[[ 0.8002082 ]\n",
      " [ 0.9491173 ]\n",
      " [ 0.9568032 ]\n",
      " [-0.00561397]\n",
      " [-0.01975284]], \n",
      "True label:\n",
      "[1. 1. 1. 0. 0.], \n",
      "Loss:0.477, \n",
      "Accuracy:99.20%\n",
      "Prediction:\n",
      "[[ 0.82329744]\n",
      " [ 0.9555538 ]\n",
      " [ 0.9567642 ]\n",
      " [-0.00367404]\n",
      " [-0.01854965]], \n",
      "True label:\n",
      "[1. 1. 1. 0. 0.], \n",
      "Loss:0.478, \n",
      "Accuracy:99.00%\n",
      "Prediction:\n",
      "[[ 0.835451  ]\n",
      " [ 0.95918536]\n",
      " [ 0.95598614]\n",
      " [-0.0030889 ]\n",
      " [-0.0174399 ]], \n",
      "True label:\n",
      "[1. 1. 1. 0. 0.], \n",
      "Loss:0.479, \n",
      "Accuracy:99.20%\n",
      "Prediction:\n",
      "[[ 0.84221035]\n",
      " [ 0.9606103 ]\n",
      " [ 0.9549068 ]\n",
      " [-0.00168781]\n",
      " [-0.01796536]], \n",
      "True label:\n",
      "[1. 1. 1. 0. 0.], \n",
      "Loss:0.480, \n",
      "Accuracy:99.40%\n",
      "Prediction:\n",
      "[[ 0.8765733 ]\n",
      " [ 0.9646958 ]\n",
      " [ 0.9616034 ]\n",
      " [-0.00129069]\n",
      " [-0.0170506 ]], \n",
      "True label:\n",
      "[1. 1. 1. 0. 0.], \n",
      "Loss:0.480, \n",
      "Accuracy:99.40%\n",
      "Prediction:\n",
      "[[ 0.8904757 ]\n",
      " [ 0.9708121 ]\n",
      " [ 0.9633705 ]\n",
      " [ 0.0023185 ]\n",
      " [-0.01840391]], \n",
      "True label:\n",
      "[1. 1. 1. 0. 0.], \n",
      "Loss:0.481, \n",
      "Accuracy:99.40%\n",
      "Prediction:\n",
      "[[ 0.90930843]\n",
      " [ 0.97746944]\n",
      " [ 0.9696387 ]\n",
      " [ 0.00980785]\n",
      " [-0.01969657]], \n",
      "True label:\n",
      "[1. 1. 1. 0. 0.], \n",
      "Loss:0.482, \n",
      "Accuracy:99.60%\n",
      "Prediction:\n",
      "[[ 0.92030525]\n",
      " [ 0.9856473 ]\n",
      " [ 0.97986007]\n",
      " [ 0.00625473]\n",
      " [-0.02434401]], \n",
      "True label:\n",
      "[1. 1. 1. 0. 0.], \n",
      "Loss:0.485, \n",
      "Accuracy:99.60%\n"
     ]
    }
   ],
   "source": [
    "# %load playground_train.py\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.layers import fully_connected\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "from dataset import * #可以直接使用dataset里面的函数\n",
    "\n",
    "\n",
    "# get data from dataset module, which is\n",
    "data, label = get_samples(classify_circle_data, 500, 0.1)\n",
    "\n",
    "# define data in default graph\n",
    "X = tf.placeholder(dtype=tf.float32, shape=(None, 2), name=\"input\")\n",
    "Y = tf.placeholder(dtype=tf.float32, shape=None, name=\"label\")\n",
    "\n",
    "# try two hidden layers with 4 nodes each(3 layers in total)\n",
    "n_hidden1 = 4\n",
    "n_hidden2 = 4\n",
    "n_output = 1\n",
    "with tf.name_scope(\"dnn_circle\"):\n",
    "    hidden1 = fully_connected(X, n_hidden1, tf.nn.relu, scope=\"hidden1\")\n",
    "    hidden2 = fully_connected(hidden1, n_hidden2, tf.nn.relu, scope=\"hidden2\")\n",
    "    # only affine mapping, before activation function\n",
    "    logits = fully_connected(hidden2, n_output, scope=\"output\", activation_fn=None)\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    pred_y = tf.nn.sigmoid(logits)\n",
    "    xentropy = tf.nn.sigmoid_cross_entropy_with_logits(labels=Y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "    # loss = tf.reduce_mean(tf.square((pred_y - Y)))\n",
    "learning_rate = 0.1\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "# 以准确率作为评价标准\n",
    "with tf.name_scope(\"eval\"):\n",
    "    # correct = tf.nn.in_top_k(logits, Y, 1)  # 多分类问题\n",
    "    concat_logits = tf.concat([tf.zeros_like(logits, dtype=tf.float32), logits], axis=1)\n",
    "    correct = tf.nn.in_top_k(concat_logits, tf.cast(Y, tf.int32), 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "init = tf.global_variables_initializer()\n",
    "n_epochs = 400\n",
    "batch_size = 50\n",
    "# 98.2%准确率\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    num = data.shape[0]\n",
    "    print(\"Model 1: circle data\")\n",
    "    for epoch in range(n_epochs):\n",
    "        for iter in range(num // batch_size):\n",
    "            X_batch = data[iter*batch_size: (iter+1)*batch_size, :]\n",
    "            Y_batch = label[iter*batch_size: (iter+1)*batch_size]\n",
    "            sess.run(training_op, feed_dict={X: X_batch, Y: Y_batch})\n",
    "\n",
    "        if not ((epoch) % 50):\n",
    "            preds, l, acc = sess.run([pred_y, loss, accuracy],\n",
    "                                     feed_dict={X: data, Y: label})\n",
    "            print(\"Prediction:\\n{}, \\nTrue label:\\n{},\"\n",
    "                  \" \\nLoss:{:.3f}, \\nAccuracy:{:.2%}\".format(preds[::100], label[::100], l, acc))\n",
    "\n",
    "\n",
    "# Model 2: Gauss data\n",
    "g2 = tf.Graph()\n",
    "with g2.as_default():\n",
    "    data, label = get_samples(classify_two_gauss_data, 500, 0.1)\n",
    "    # define data in default graph\n",
    "    X = tf.placeholder(dtype=tf.float32, shape=(None, 2), name=\"input\")\n",
    "    Y = tf.placeholder(dtype=tf.float32, shape=None, name=\"label\")\n",
    "\n",
    "    # try two hidden layers with 4 nodes each(3 layers in total)\n",
    "    n_hidden1 = 4\n",
    "    n_hidden2 = 4\n",
    "    n_output = 1\n",
    "    with g2.name_scope(\"dnn_gauss\"):\n",
    "        hidden1 = fully_connected(X, n_hidden1, tf.nn.relu, scope=\"hidden1\")\n",
    "        hidden2 = fully_connected(hidden1, n_hidden2, tf.nn.relu, scope=\"hidden2\")\n",
    "        # only affine mapping, before activation function\n",
    "        logits = fully_connected(hidden2, n_output, scope=\"output\", activation_fn=None)\n",
    "    with g2.name_scope(\"loss\"):\n",
    "        # pred_y = tf.nn.sigmoid(logits)\n",
    "        # xentropy = tf.nn.sigmoid_cross_entropy_with_logits(labels=Y, logits=logits)\n",
    "        # loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "        pred_y = tf.nn.relu(logits)\n",
    "        loss = tf.reduce_mean(tf.square(pred_y-Y))\n",
    "    learning_rate = 0.1\n",
    "    with g2.name_scope(\"train\"):\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "        training_op = optimizer.minimize(loss)\n",
    "    with g2.name_scope(\"eval\"):\n",
    "        concat_logits = tf.concat([tf.zeros_like(pred_y, tf.float32)+0.5, pred_y], axis=1)\n",
    "        correct = tf.nn.in_top_k(concat_logits, tf.cast(Y, tf.int32), 1)\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    init = tf.global_variables_initializer()\n",
    "    batch_size = 50\n",
    "    n_epochs = 400\n",
    "    with tf.Session(graph=g2) as sess:\n",
    "        init.run()\n",
    "        print(\"Model 2: Gauss data\")\n",
    "        for epoch in range(n_epochs):\n",
    "            num = data.shape[0]\n",
    "            for iter in range(num // batch_size):\n",
    "                X_batch = data[iter*batch_size:(iter+1)*batch_size, :]\n",
    "                Y_batch = label[iter*batch_size:(iter+1)*batch_size]\n",
    "                sess.run(training_op, feed_dict={X: X_batch, Y: Y_batch})\n",
    "            if not ((epoch) % 50):\n",
    "                preds, l, acc = sess.run([pred_y, loss, accuracy], feed_dict={X: data, Y: label})\n",
    "                print(\"Prediction:\\n{}, \\nTrue label:\\n{},\"\n",
    "                      \" \\nLoss:{:.3f}, \\nAccuracy:{:.2%}\".format(preds[::50], label[::50], l, acc))\n",
    "\n",
    "# Model 3: xor data | harder than the previous two models\n",
    "# smaller batch_size and little bit larger learning_rate\n",
    "# > 97% accuracy\n",
    "g3 = tf.Graph()\n",
    "with g3.as_default():\n",
    "    data, label = get_samples(classify_xor_data, 500, 0.05)\n",
    "    # define data in default graph\n",
    "    X = tf.placeholder(dtype=tf.float32, shape=(None, 2), name=\"input\")\n",
    "    Y = tf.placeholder(dtype=tf.float32, shape=None, name=\"label\")\n",
    "\n",
    "    # try two hidden layers with 4 nodes each(3 layers in total)\n",
    "    n_hidden1 = 4\n",
    "    n_hidden2 = 4\n",
    "    n_output = 1\n",
    "\n",
    "    # self-define leaky_relu\n",
    "    # robuster than relu\n",
    "    def leaky_relu(x, leak=0.2, name=\"leaky_relu\"):\n",
    "        with tf.variable_scope(name):\n",
    "            f1 = 0.5 * (1 + leak)\n",
    "            f2 = 0.5 * (1 - leak)\n",
    "            return f1 * x + f2 * tf.abs(x)\n",
    "    with g3.name_scope(\"dnn_xor\"):\n",
    "        hidden1 = fully_connected(X, n_hidden1, leaky_relu, scope=\"hidden1\")\n",
    "        hidden2 = fully_connected(hidden1, n_hidden2, leaky_relu, scope=\"hidden2\")\n",
    "        # only affine mapping, before activation function\n",
    "        logits = fully_connected(hidden2, n_output, scope=\"output\", activation_fn=None)\n",
    "    with g3.name_scope(\"loss\"):\n",
    "        pred_y = tf.nn.sigmoid(logits)\n",
    "        xentropy = tf.nn.sigmoid_cross_entropy_with_logits(labels=Y, logits=logits)\n",
    "        loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "        # pred_y = tf.nn.relu(logits)\n",
    "        # loss = tf.reduce_mean(tf.square(pred_y-Y))\n",
    "    learning_rate = tf.placeholder(tf.float32)\n",
    "    with g3.name_scope(\"train\"):\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "        training_op = optimizer.minimize(loss)\n",
    "    with g3.name_scope(\"eval\"):\n",
    "        # concat_logits = tf.concat([tf.zeros_like(logits, tf.float32), logits], axis=1)\n",
    "        concat_logits = tf.concat([tf.zeros_like(pred_y, tf.float32)+0.5, pred_y], axis=1)\n",
    "        correct = tf.nn.in_top_k(concat_logits, tf.cast(Y, tf.int32), 1)\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    init = tf.global_variables_initializer()\n",
    "    n_epochs = 400\n",
    "    batch_size = 5\n",
    "    with tf.Session(graph=g3) as sess:\n",
    "        init.run()\n",
    "        print(\"Model 3: xor data\")\n",
    "        for epoch in range(n_epochs):\n",
    "            num = data.shape[0]\n",
    "            if epoch < 200:\n",
    "                lr = 0.12\n",
    "            else:\n",
    "                lr = 0.1\n",
    "            for iter in range(num // batch_size):\n",
    "                X_batch = data[iter*batch_size:(iter+1)*batch_size, :]\n",
    "                Y_batch = label[iter*batch_size:(iter+1)*batch_size]\n",
    "                sess.run(training_op, feed_dict={X: X_batch, Y: Y_batch, learning_rate: lr})\n",
    "\n",
    "            if not (epoch % 30):\n",
    "                preds, l, acc = sess.run([pred_y, loss, accuracy], feed_dict={X: data, Y: label})\n",
    "                print(\"Prediction:\\n{}, \\nTrue label:\\n{},\"\n",
    "                      \" \\nLoss:{:.3f}, \\nAccuracy:{:.2%}\".format(preds[::100], label[::100], l, acc))\n",
    "\n",
    "# Model 4: Spiral data\n",
    "# hardest, use larger scale model to train\n",
    "g4 = tf.Graph()\n",
    "with g4.as_default():\n",
    "    data, label = get_samples(classify_spiral_data, 500, 0.05)\n",
    "    # define data in default graph\n",
    "    X = tf.placeholder(dtype=tf.float32, shape=(None, 2), name=\"input\")\n",
    "    Y = tf.placeholder(dtype=tf.float32, shape=None, name=\"label\")\n",
    "\n",
    "    # try five hidden layers(6 layers in total)\n",
    "    n_hidden1 = 8\n",
    "    n_hidden2 = 8\n",
    "    n_hidden3 = 7\n",
    "    n_hidden4 = 6\n",
    "    n_hidden5 = 5\n",
    "    n_output = 1\n",
    "\n",
    "    # self-define leaky_relu\n",
    "    # robuster than relu\n",
    "    def leaky_relu(x, leak=0.2, name=\"leaky_relu\"):\n",
    "        with tf.variable_scope(name):\n",
    "            f1 = 0.5 * (1 + leak)\n",
    "            f2 = 0.5 * (1 - leak)\n",
    "            return f1 * x + f2 * tf.abs(x)\n",
    "    with g4.name_scope(\"dnn_spiral\"):\n",
    "        hidden1 = fully_connected(X, n_hidden1, leaky_relu, scope=\"hidden1\")\n",
    "        hidden2 = fully_connected(hidden1, n_hidden2, leaky_relu, scope=\"hidden2\")\n",
    "        hidden3 = fully_connected(hidden2, n_hidden3, leaky_relu, scope=\"hidden3\")\n",
    "        hidden4 = fully_connected(hidden3, n_hidden4, leaky_relu, scope=\"hidden4\")\n",
    "        hidden5 = fully_connected(hidden4, n_hidden5, leaky_relu, scope=\"hidden5\")\n",
    "        # only affine mapping, before activation function\n",
    "        logits = fully_connected(hidden5, n_output, scope=\"output\", activation_fn=None)\n",
    "    with g4.name_scope(\"loss\"):\n",
    "        pred_y = leaky_relu(logits)\n",
    "        # xentropy = tf.nn.sigmoid_cross_entropy_with_logits(labels=Y, logits=logits)\n",
    "        # loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "        loss = tf.reduce_mean(tf.square(pred_y-Y))\n",
    "    learning_rate = tf.placeholder(tf.float32)\n",
    "    with g4.name_scope(\"train\"):\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "        training_op = optimizer.minimize(loss)\n",
    "    with g4.name_scope(\"eval\"):\n",
    "        concat_logits = tf.concat([tf.zeros_like(logits, tf.float32) + 0.5, logits], axis=1)\n",
    "        correct = tf.nn.in_top_k(concat_logits, tf.cast(Y, tf.int32), 1)\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    init = tf.global_variables_initializer()\n",
    "    n_epochs = 1000\n",
    "    batch_size = 15\n",
    "    with tf.Session(graph=g4) as sess:\n",
    "        init.run()\n",
    "        print(\"Model 4: spiral data\")\n",
    "        # to_shuffle = True\n",
    "        for epoch in range(n_epochs):\n",
    "            num = data.shape[0]\n",
    "            if epoch < 400:\n",
    "                lr = 0.12\n",
    "\n",
    "            # elif to_shuffle:\n",
    "            #     np.random.shuffle(data[0])\n",
    "            #     np.random.shuffle(data[1])\n",
    "            #     np.random.shuffle(label)\n",
    "            #     to_shuffle = False\n",
    "            #     lr=0.09\n",
    "            #     batch_size = 20\n",
    "            else:\n",
    "                lr = 0.1\n",
    "            for iter in range(num // batch_size):\n",
    "                X_batch = data[iter*batch_size:(iter+1)*batch_size, :]\n",
    "                Y_batch = label[iter*batch_size:(iter+1)*batch_size]\n",
    "                sess.run(training_op, feed_dict={X: X_batch, Y: Y_batch, learning_rate: lr})\n",
    "\n",
    "            if not (epoch % 50):\n",
    "                # sess.run(training_op, feed_dict={X: data, Y: label})\n",
    "                preds, l, acc = sess.run([pred_y, loss, accuracy], feed_dict={X: data, Y: label})\n",
    "                print(\"Prediction:\\n{}, \\nTrue label:\\n{},\"\n",
    "                      \" \\nLoss:{:.3f}, \\nAccuracy:{:.2%}\".format(preds[::100], label[::100], l, acc))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
