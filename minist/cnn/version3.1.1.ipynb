{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import urllib\n",
    "from datetime import datetime\n",
    "\n",
    "from urllib.request import urlretrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGDIR = '../tensorboard/cnn/v3.1/'\n",
    "GITHUB_URL ='https://raw.githubusercontent.com/mamcgrath/TensorBoard-TF-Dev-Summit-Tutorial/master/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-bc5dd4a46994>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\Jacky' PC\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\Jacky' PC\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ../tensorboard/cnn/v3.1/data\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\Jacky' PC\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ../tensorboard/cnn/v3.1/data\\train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\Jacky' PC\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting ../tensorboard/cnn/v3.1/data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ../tensorboard/cnn/v3.1/data\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\Jacky' PC\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('../tensorboard/cnn/v3.1/sprite_1024.png',\n",
       " <http.client.HTTPMessage at 0x25a403e8198>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### MNIST EMBEDDINGS ###\n",
    "mnist = tf.contrib.learn.datasets.mnist.read_data_sets(train_dir=LOGDIR + 'data', one_hot=True)\n",
    "### Get a sprite and labels file for the embedding projector ###\n",
    "urlretrieve(GITHUB_URL + 'labels_1024.tsv', LOGDIR + 'labels_1024.tsv')\n",
    "urlretrieve(GITHUB_URL + 'sprite_1024.png', LOGDIR + 'sprite_1024.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 卷积网络层的定义,tf.nn.conv2d是TensorFlow里面实现卷积的函数（读者也可以自己实现卷积操作）。其中：\n",
    "    + x是输入，即训练时输入的每一个batch。\n",
    "    + W是CNN中的卷积核，它要求是一个Tensor，具有[filter_height, filter_width, in_channels, out_channels]这样的shape，具体含义是[卷积核的高度，卷积核的宽度，图像通道数，卷积核个数]，要求类型与参数input相同。(图像通道即颜色的维度，卷积核个数代表卷积核有几层)\n",
    "    + strides：卷积时在图像每一维的步长，一个一维的向量，本例中每个步长为1. [1, 1, 1, 1]\n",
    "    + padding：string类型的量，只能是\"SAME\",\"VALID\"其中之一，这个值决定了不同的卷积方式，其中SAME为零填充保持大小不变，VALID没有零填充\n",
    "\n",
    "\n",
    "+ max pooling 层的定义,其中：\n",
    "    + x 是需要池化的输入，一般池化层接在卷积层后面，所以输入通常是feature map，依然是[batch, height, width, channels]这样的shape。\n",
    "    + ksize：池化窗口的大小，取一个四维向量，一般是[1, height, width, 1]，因为我们不想在batch和channels上做池化，所以这两个维度设为了1\n",
    "    + strides：和卷积层的定义类似，窗口在每一个维度上滑动的步长，一般也是[1, stride,stride, 1]\n",
    "    + padding：和卷积层的定义类似，可以取'VALID' 或者'SAME'\n",
    "    + 返回一个Tensor，类型不变，shape是[batch, height, width, channels]的形式\n",
    "    \n",
    "    \n",
    "+ padding的形式：\"VALID\",\"SAME\":\n",
    "    + VALID：比较容易理解，filter全部在image里面\n",
    "        + SAME：满足$n_{out}=\\lceil \\frac {n_{out}} {s}\\rceil$，即当步长s为1时，大小保持不变；各个方向补充0的规则为\n",
    "            + $pad_h = max[( o_h -1 ) × s_h + f_h - i_h ， 0]$\n",
    "            + $pad_{top} = \\lfloor pad_h / 2 \\rfloor$  # 注意此处向下取整\n",
    "            + $pad_{bottom} = pad_h - pad_{top}$\n",
    "            + $pad_w = max[( o_w -1 ) × s_w + f_w - i_w ， 0]$\n",
    "            + $pad_{left} = \\lfloor pad_w / 2 \\rfloor$  # 注意此处向下取整\n",
    "            + $pad_{right} = pad_w - pad_{left}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add convolution layer\n",
    "def conv_layer(input, size_in, size_out, name=\"conv\"):\n",
    "  with tf.name_scope(name): #设立名字域，以参数name命名\n",
    "    w = tf.Variable(tf.truncated_normal([5, 5, size_in, size_out], stddev=0.1), name=\"W\")\n",
    "    b = tf.Variable(tf.constant(0.1, shape=[size_out]), name=\"B\")\n",
    "    conv = tf.nn.conv2d(input, w, strides=[1, 1, 1, 1], padding=\"SAME\") #第一层卷积层，零填充使得卷积后大小不变(步长为1时)\n",
    "    act = tf.nn.relu(conv + b) #第二层激活层，b用在cnv2d函数外面\n",
    "    tf.summary.histogram(\"weights\", w)#tensorboard中显示直方图\n",
    "    tf.summary.histogram(\"biases\", b)\n",
    "    tf.summary.histogram(\"activations\", act)\n",
    "    return tf.nn.max_pool(act, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\")#第三次池化层，最大池化\n",
    "\n",
    "\n",
    "# Add fully connected layer 输出层不应该加激活函数\n",
    "def fc_layer(input, size_in, size_out, name=\"fc\"):\n",
    "  with tf.name_scope(name):\n",
    "    w = tf.Variable(tf.truncated_normal([size_in, size_out], stddev=0.1), name=\"W\")\n",
    "    b = tf.Variable(tf.constant(0.1, shape=[size_out]), name=\"B\")\n",
    "    act = tf.nn.relu(tf.matmul(input, w) + b)\n",
    "    tf.summary.histogram(\"weights\", w)\n",
    "    tf.summary.histogram(\"biases\", b)\n",
    "    tf.summary.histogram(\"activations\", act)\n",
    "    return act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_model(learning_rate, use_two_conv, use_two_fc, hparam):\n",
    "  tf.reset_default_graph()\n",
    "  sess = tf.Session()\n",
    "  TIMESTAMP = \",{0:%Y-%m-%dT%H-%M-%S/}\".format(datetime.now()) #增加时间路径，使得多次运行不重合\n",
    "\n",
    "  # Setup placeholders, and reshape the data\n",
    "  x = tf.placeholder(tf.float32, shape=[None, 784], name=\"x\")\n",
    "  x_image = tf.reshape(x, [-1, 28, 28, 1]) #-1表示使得总乘数不变的数\n",
    "  tf.summary.image('input', x_image, 3)\n",
    "  y = tf.placeholder(tf.float32, shape=[None, 10], name=\"labels\")\n",
    "\n",
    "  if use_two_conv:\n",
    "    conv1 = conv_layer(x_image, 1, 32, \"conv1\") #输出为14*14，32个卷积核\n",
    "    conv_out = conv_layer(conv1, 32, 64, \"conv2\") #输出为7*7，64个卷积核\n",
    "  else:\n",
    "    #conv1 = conv_layer(x_image, 1, 64, \"conv\") #输出为14*14，64个卷积核\n",
    "    #conv_out = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\") #池化了两次？可去掉？\n",
    "    #不可去掉，有必要，输出为7*7，64个卷积核\n",
    "    \n",
    "    #另一种做法：\n",
    "    conv_out = conv_layer(x_image, 1, 16, \"conv\") #输出为14*14，16个卷积核，其中14*14*16=7*7*64\n",
    "    \n",
    "  flattened = tf.reshape(conv_out, [-1, 7 * 7 * 64]) #将数据由7*7*64变成1维\n",
    "\n",
    "\n",
    "  if use_two_fc:\n",
    "    fc1 = fc_layer(flattened, 7 * 7 * 64, 1024, \"fc1\") #将7*7*64维变成1024维\n",
    "    embedding_input = fc1  #embedding输入,即最后一层的输入\n",
    "    embedding_size = 1024  #embedding数据维度\n",
    "    logits = fc_layer(fc1, 1024, 10, \"fc2\") #将1024维变成10维\n",
    "  else:\n",
    "    embedding_input = flattened\n",
    "    embedding_size = 7*7*64\n",
    "    logits = fc_layer(flattened, 7*7*64, 10, \"fc\") #将7*7*64维变成10维\n",
    "\n",
    "  with tf.name_scope(\"xent\"): #交叉熵\n",
    "    xent = tf.reduce_mean(\n",
    "        tf.nn.softmax_cross_entropy_with_logits(\n",
    "            logits=logits, labels=y), name=\"xent\")\n",
    "    tf.summary.scalar(\"xent\", xent)\n",
    "\n",
    "  with tf.name_scope(\"train\"): #优化\n",
    "    train_step = tf.train.AdamOptimizer(learning_rate).minimize(xent)\n",
    "\n",
    "  with tf.name_scope(\"accuracy\"): #准确率\n",
    "    correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    tf.summary.scalar(\"accuracy\", accuracy)\n",
    "\n",
    "  summ = tf.summary.merge_all()\n",
    "\n",
    "\n",
    "  #默认情况下，embedding projector 会用 PCA 主成分分析方法将高维数据投影到 3D 空间, 还有一种投影方法是 T-SNE。\n",
    "  embedding = tf.Variable(tf.zeros([1024, embedding_size]), name=\"test_embedding\")\n",
    "  assignment = embedding.assign(embedding_input)\n",
    "  saver = tf.train.Saver()\n",
    "\n",
    "  sess.run(tf.global_variables_initializer())\n",
    "  writer = tf.summary.FileWriter(LOGDIR + hparam + TIMESTAMP) #由summary,可导出tensorboard --logdir ../tensorboard/cnn/v3.1\n",
    "  writer.add_graph(sess.graph)\n",
    "  \n",
    "  config = tf.contrib.tensorboard.plugins.projector.ProjectorConfig()\n",
    "  embedding_config = config.embeddings.add()\n",
    "  embedding_config.tensor_name = embedding.name\n",
    "  embedding_config.sprite.image_path = '../sprite_1024.png'\n",
    "  embedding_config.metadata_path = '../labels_1024.tsv'\n",
    "  # Specify the width and height of a single thumbnail.\n",
    "  embedding_config.sprite.single_image_dim.extend([28, 28])\n",
    "  tf.contrib.tensorboard.plugins.projector.visualize_embeddings(writer, config)\n",
    "\n",
    "  for i in range(2001):\n",
    "    batch = mnist.train.next_batch(100) \n",
    "    if i % 5 == 0:\n",
    "      [train_accuracy, s] = sess.run([accuracy, summ], feed_dict={x: batch[0], y: batch[1]}) #batch[0]为x图片数据，batch[1]为y标签\n",
    "      writer.add_summary(s, i)\n",
    "    if i % 500 == 0:\n",
    "      sess.run(assignment, feed_dict={x: mnist.test.images[:1024], y: mnist.test.labels[:1024]}) #测试集的前1024个数据作为embedding的输入\n",
    "      saver.save(sess, os.path.join(LOGDIR+hparam+TIMESTAMP, \"model.ckpt\"), i)\n",
    "    sess.run(train_step, feed_dict={x: batch[0], y: batch[1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_hparam_string(learning_rate, use_two_fc, use_two_conv):\n",
    "    conv_param = \"conv=2\" if use_two_conv else \"conv=1\"\n",
    "    fc_param = \"fc=2\" if use_two_fc else \"fc=1\"\n",
    "    return \"lr_%.0E,%s,%s\" % (learning_rate, conv_param, fc_param)\n",
    "\n",
    "def main():\n",
    "  # You can try adding some more learning rates\n",
    "  for learning_rate in [1E-3,1E-4]:\n",
    "\n",
    "    # Include \"False\" as a value to try different model architectures\n",
    "    for use_two_fc in [True,False]:\n",
    "        for use_two_conv in [True,False]:\n",
    "            # Construct a hyperparameter string for each one (example: \"lr_1E-3,fc=2,conv=2)\n",
    "            hparam = make_hparam_string(learning_rate, use_two_fc, use_two_conv)\n",
    "            print('Starting run for %s' % hparam)\n",
    "\n",
    "            # Actually run with the new settings\n",
    "            mnist_model(learning_rate, use_two_fc, use_two_conv, hparam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run for lr_1E-03,conv=2,fc=2\n",
      "WARNING:tensorflow:From <ipython-input-5-8d5c69fdfbfa>:39: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "Starting run for lr_1E-03,conv=1,fc=2\n",
      "Starting run for lr_1E-03,conv=2,fc=1\n",
      "Starting run for lr_1E-03,conv=1,fc=1\n",
      "Starting run for lr_1E-04,conv=2,fc=2\n",
      "Starting run for lr_1E-04,conv=1,fc=2\n",
      "Starting run for lr_1E-04,conv=2,fc=1\n",
      "Starting run for lr_1E-04,conv=1,fc=1\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "  main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../tensorboard/cnn/v3.1/\n"
     ]
    }
   ],
   "source": [
    "print(LOGDIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.test.labels[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
